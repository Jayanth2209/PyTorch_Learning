{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Basics & Linear Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMRc-SbMW8Ak"
      },
      "source": [
        "## Install PyTorch\n",
        "````\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8mHW5LAXOV7"
      },
      "source": [
        "### Import Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inW6QngXXWYS"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcmGwrmGXhHZ"
      },
      "source": [
        "### What is a Tensor?\n",
        "A Tensor is a number, vector, matrix, or any n-dimensional array. A tensor has an additional property of uniformity in the data type of all entries and that they are always of a proper shape i.e., the lenghts of rows are all same, and the same goes with columns.\n",
        "\n",
        "[Tensors: Reference](https://pytorch.org/docs/stable/torch.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au9vcW9QXtMi"
      },
      "source": [
        "t0 = torch.tensor([[1,2,3],\n",
        "                  [4,5,6],\n",
        "                  [7,8,9]])\n",
        "print(t0)\n",
        "print(t0.dtype)\n",
        "print(t0.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7bXsHZOXvrv"
      },
      "source": [
        "t1 = torch.tensor([[1,2,3],\n",
        "                  [4,5,6],\n",
        "                  [7.0,8,9]])\n",
        "print(t1)\n",
        "print(t1.dtype)\n",
        "print(t1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YH_xcrDYNZg"
      },
      "source": [
        "Now, t1 is a 3x3 Tensor with dtype \"float32\". Since one entry (7.0) is a floating point entry, the rest will be converted to FP too.\n",
        "\n",
        "Here is an example of a 3D Tensor of size 2x3x4. Similarly nD Tensors can also be constructed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxhkq9d-YTaY"
      },
      "source": [
        "t2 = torch.tensor([[[1,2,3,4],\n",
        "                   [5,6,7,8],\n",
        "                   [9,10,11,12]],\n",
        "                   [[9,10,11,12],\n",
        "                   [13,14,15,16],\n",
        "                   [17,18,19,20]]])\n",
        "print(t2)\n",
        "print(t2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1VS49qXYiUy"
      },
      "source": [
        "### Gradients\n",
        "We can perform arithmetic operations on Torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF1NU33sYoN5"
      },
      "source": [
        "x = torch.tensor(2.,requires_grad=True)\n",
        "w = torch.tensor(3.,requires_grad=True)\n",
        "b = torch.tensor(7.,requires_grad=True)\n",
        "y = w*x + b\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZV9-3tfYtbf"
      },
      "source": [
        "If you print **y**, you can see that it is a tensor with one entry = 13. We set ````requires_grad=True```` for making the tensors utilizable for certain functions. For example, we can perform Backprop as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xfpCe_KY--N"
      },
      "source": [
        "y.backward()\n",
        "print('dy/dx:', x.grad)\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohJM9rmRZMM0"
      },
      "source": [
        "We obtain derivatives of y with respect to x,w and b i.e., dy/dx, dy/dw and dy/db as 3,2 and 1 respectively. If we had set ````requires_grad=False````, these would print out as ````None````. \n",
        "\n",
        "Default is ````requires_grad=False````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6ROzifxZqCI"
      },
      "source": [
        "### Some Torch Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiWD4WizZuK2"
      },
      "source": [
        "t2 = torch.ones(3,4)\n",
        "t3 = torch.full((3,4),7.384)\n",
        "t4 = torch.cat((t2,t3))\n",
        "t5 = t2.reshape(3,2,2)\n",
        "print(f't2: {t2}\\n')\n",
        "print(f't3: {t3}\\n')\n",
        "print(f't4: {t4}\\n')\n",
        "print(f't5: {t5}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSnrfwPJaM0d"
      },
      "source": [
        "### Numpy & Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JJDBBaZaOwF"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hb_tOvxaSFN"
      },
      "source": [
        "##### **Creating a Numpy Array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF5mNF1EaXZ-"
      },
      "source": [
        "n1 = np.array([[1, 2, 3], [3., 4, 5]])\n",
        "print(n1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXJcpy_Vaau5"
      },
      "source": [
        "Note that dtype is float due to the presence of a one \"3.\". This is because numpy array has uniformity too.\n",
        "\n",
        "**Converting Numpy array to Torch Tensor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzrWjMksaj5f"
      },
      "source": [
        "t6 = torch.from_numpy(n1)\n",
        "print(t6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCQC-ga0bJ70"
      },
      "source": [
        "**Converting Torch Tensor to Numpy Array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa5sXu2MbPlq"
      },
      "source": [
        "n2 = t6.numpy()\n",
        "print(n2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg1OlWocboiN"
      },
      "source": [
        "# Linear Regression\n",
        "**Y = WX + B**\n",
        "Y = Output, X = Input, W = Weights and B = Bias. Mathematically, **Y = X x W<sup>T</sup> + B**\n",
        "\n",
        "Let us consider the following input dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt4K2LJfcdmJ"
      },
      "source": [
        "| Rainfall (X1) | Temperature (X2) | Yield (Y) |\n",
        "|      :-:      |      :-:         |      :-:  |\n",
        "| 67 | 73 | 56 |\n",
        "| 88 | 91 | 81 |\n",
        "| 134 | 87 | 119 |\n",
        "| 43 | 102 | 22 |\n",
        "| 96 | 69 | 103 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX16y5aYclGo"
      },
      "source": [
        "So, our Input Array X is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye1fsnRacqUG"
      },
      "source": [
        "X = np.array([[67,73],\n",
        "              [88,91],\n",
        "              [134,87],\n",
        "              [43,102],\n",
        "              [96,69]],dtype='float32')\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LiczXJ6cxB4"
      },
      "source": [
        "Our actual output vector Y is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oL6f0RRc2ly"
      },
      "source": [
        "Y = np.array([56,81,119,22,103],dtype='float32')\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVDAujjSc4rs"
      },
      "source": [
        "Convert these to Torch Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppfz__0ZdAiw"
      },
      "source": [
        "X = torch.from_numpy(X)\n",
        "Y = torch.from_numpy(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bv_UQaCdC8m"
      },
      "source": [
        "Now, we need to obtain the weights W and biases B, of the best fit to this dataset. Initialize W and B with random values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59yIrTiEkvR2"
      },
      "source": [
        "### Initialize Weights and Biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kKsl2--dFoA"
      },
      "source": [
        "W = torch.randn(1,2,requires_grad=True)   # Because W Transpose should be 2x1\n",
        "B = torch.randn(5,1,requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is97vJxEdHxO"
      },
      "source": [
        "### Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6quc4tndLM5"
      },
      "source": [
        "def model(X):\n",
        "    return X @ W.t() + B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXZ7rSnxdNME"
      },
      "source": [
        "**@** represents matrix multiplication in PyTorch and **.t()** returns Transpose of a tensor Let our predictions be **Y_**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6v5Rzj4dXZf"
      },
      "source": [
        "Y_ = model(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf2AnoNEdbVG"
      },
      "source": [
        "### Loss Function\n",
        "Define the Loss Function. Considering **MSE** (Mean Squared Error) Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrnHkxWXdkTs"
      },
      "source": [
        "def MSE(y,h):\n",
        "    diff = h - y\n",
        "    return torch.sum(diff**2)/diff.numel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6EhXPzJdoWK"
      },
      "source": [
        "**torch.sum()** returns sum of elements of a tensor and .numel() returns the number of elements in a tensor.\n",
        "\n",
        "**Compute the Loss for our model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSXLV8AQd1p_"
      },
      "source": [
        "Loss = MSE(Y,Y_)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxWfDti_eC6D"
      },
      "source": [
        "### Back Propogation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njDQ6m20eIC_"
      },
      "source": [
        "Loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxku7J2meK-l"
      },
      "source": [
        "### Compute Gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25rb-SE1eSYv"
      },
      "source": [
        "W.grad     \n",
        "B.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA88A0jfeX-4"
      },
      "source": [
        "### Updation Step\n",
        "Updating our weights W and biases B. Consider a learning rate of **a**. Let a = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrYr-Xp-egVM"
      },
      "source": [
        "a = 1e-5\n",
        "with torch.no_grad():\n",
        "    W -= a*(W.grad)\n",
        "    B -= a*(B.grad) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPr3HoPZemFn"
      },
      "source": [
        "We use ````torch.no_grad()```` to indicate to PyTorch that we shouldn't track, calculate, or modify gradients while updating the weights and biases.\n",
        "\n",
        "Now, reset the gradients to zero. We need to do this because PyTorch accumulates gradients. Otherwise, the next time we invoke backprop on the loss, the new gradient values are added to the existing gradients, which may lead to unexpected results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCpEYMjJevq0"
      },
      "source": [
        "W.grad.zero_()\n",
        "B.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk3rnmwWezYg"
      },
      "source": [
        "### Train for multiple Epochs\n",
        "Repeat the steps until the loss is significantly minimized. For **N** Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgbEpLyse44J"
      },
      "source": [
        "N = 100\n",
        "for i in range(N):\n",
        "    Y_ = model(X)\n",
        "    Loss = MSE(Y, Y_)\n",
        "    Loss.backward()\n",
        "    with torch.no_grad():\n",
        "        W -= W.grad * a\n",
        "        B -= B.grad * a\n",
        "        W.grad.zero_()\n",
        "        B.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt2yGfNtfBVY"
      },
      "source": [
        "Compute the Loss now and verify that it is lower. Compare the actual outputs and predicted outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHXlSs3efEZf"
      },
      "source": [
        "Loss = MSE(Y,Y_)\n",
        "print(f'MSE Loss: {Loss}\\n')\n",
        "print(f'Predicted Output: {Y_}\\n')\n",
        "print(f'Actual Output: {Y}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPC5qImYfrDS"
      },
      "source": [
        "## Linear Regression using PyTorch packages\n",
        "PyTorch provides several built-in functions and classes to make it easy to create and train models with just a few lines of code.\n",
        "\n",
        "Import the ````torch.nn```` package, which contains utility classes for building neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orS8yq_el1u9"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd6Rqslal6C0"
      },
      "source": [
        "Let us consider a bigger dataset, with 3 Input Parameters - Temperature, Humidity and Rainfall\n",
        "\n",
        "Represent Inputs and Outputs as matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu2CmDjEon8S"
      },
      "source": [
        "# Input (Temperature, Rainfall, Humidity)\n",
        "X = np.array([[73, 67, 43], \n",
        "              [91, 88, 64], \n",
        "              [87, 134, 58], \n",
        "              [102, 43, 37], \n",
        "              [69, 96, 70], \n",
        "              [74, 66, 43], \n",
        "              [91, 87, 65], \n",
        "              [88, 134, 59], \n",
        "              [101, 44, 37], \n",
        "              [68, 96, 71], \n",
        "              [73, 66, 44], \n",
        "              [92, 87, 64], \n",
        "              [87, 135, 57], \n",
        "              [103, 43, 36], \n",
        "              [68, 97, 70]], \n",
        "              dtype='float32')\n",
        "\n",
        "# Targets (Yield, say Mangoes and Bananas)\n",
        "Y = np.array([[56, 70], \n",
        "              [81, 101], \n",
        "              [119, 133], \n",
        "              [22, 37], \n",
        "              [103, 119],\n",
        "              [57, 69], \n",
        "              [80, 102], \n",
        "              [118, 132], \n",
        "              [21, 38], \n",
        "              [104, 118], \n",
        "              [57, 69], \n",
        "              [82, 100], \n",
        "              [118, 134], \n",
        "              [20, 38], \n",
        "              [102, 120]], \n",
        "              dtype='float32')\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "Y = torch.from_numpy(Y)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM_41IfcpTeP"
      },
      "source": [
        "### Dataset and DataLoader\n",
        "We'll create a ````TensorDataset````, which allows access to rows from inputs (X) and outputs (Y) as tuples, and provides standard APIs for working with many different types of datasets in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQldg_IBpnHk"
      },
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X45dtH3bpsau",
        "outputId": "37c9e748-dda6-478d-c2a1-f542ee55eae4"
      },
      "source": [
        "# Define dataset\n",
        "train_ds = TensorDataset(X, Y)\n",
        "print(train_ds[0:])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [ 74.,  66.,  43.],\n",
            "        [ 91.,  87.,  65.],\n",
            "        [ 88., 134.,  59.],\n",
            "        [101.,  44.,  37.],\n",
            "        [ 68.,  96.,  71.],\n",
            "        [ 73.,  66.,  44.],\n",
            "        [ 92.,  87.,  64.],\n",
            "        [ 87., 135.,  57.],\n",
            "        [103.,  43.,  36.],\n",
            "        [ 68.,  97.,  70.]]), tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 57.,  69.],\n",
            "        [ 80., 102.],\n",
            "        [118., 132.],\n",
            "        [ 21.,  38.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [ 82., 100.],\n",
            "        [118., 134.],\n",
            "        [ 20.,  38.],\n",
            "        [102., 120.]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr67afvUp-7s",
        "outputId": "8e328393-ab3d-41a6-a21c-893985f02ecf"
      },
      "source": [
        "print(train_ds[0:5])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]]), tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBk9JwosqC4_"
      },
      "source": [
        "````TensorDataset```` allows us to access a small section of the training data using the array indexing notation (````[0:5]```` in the above example). It returns a tuple with two elements. The first element contains the ````inputs X```` for the selected rows, and the second contains the ````outputs Y````."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REUxxgBaqbHw"
      },
      "source": [
        "Import ````DataLoader````, which can split the data into batches of predefined size while training. It also provides other utilities like shuffling and random sampling of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfnfafmuqBiR"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wld072S8ql0E"
      },
      "source": [
        "# Define Data Loader\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIfXUDW9qpw8",
        "outputId": "1419f77b-10a5-4e49-f627-67b1003c8ec4"
      },
      "source": [
        "for xb, yb in train_dl:\n",
        "    print(xb)\n",
        "    print(yb)\n",
        "    print('\\n')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 68.,  97.,  70.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 88., 134.,  59.],\n",
            "        [ 91.,  87.,  65.]])\n",
            "tensor([[102., 120.],\n",
            "        [ 81., 101.],\n",
            "        [ 22.,  37.],\n",
            "        [118., 132.],\n",
            "        [ 80., 102.]])\n",
            "\n",
            "\n",
            "tensor([[101.,  44.,  37.],\n",
            "        [103.,  43.,  36.],\n",
            "        [ 74.,  66.,  43.],\n",
            "        [ 73.,  67.,  43.],\n",
            "        [ 68.,  96.,  71.]])\n",
            "tensor([[ 21.,  38.],\n",
            "        [ 20.,  38.],\n",
            "        [ 57.,  69.],\n",
            "        [ 56.,  70.],\n",
            "        [104., 118.]])\n",
            "\n",
            "\n",
            "tensor([[ 87., 134.,  58.],\n",
            "        [ 73.,  66.,  44.],\n",
            "        [ 92.,  87.,  64.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [ 87., 135.,  57.]])\n",
            "tensor([[119., 133.],\n",
            "        [ 57.,  69.],\n",
            "        [ 82., 100.],\n",
            "        [103., 119.],\n",
            "        [118., 134.]])\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHfaXQXJrEeh"
      },
      "source": [
        "In each iteration, DataLoader returns one batch of data with the given batch size. \n",
        "\n",
        "If ````shuffle=True````, it shuffles the training data before creating batches. Shuffling helps randomize the input to the optimization algorithm, leading to a faster reduction in the loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCIhiD9traPF"
      },
      "source": [
        "## nn.Linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jDH3LJ2reTU"
      },
      "source": [
        "Instead of initializing the weights & biases manually, we can define the model using the ````nn.Linear```` class, which does it automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J5V3n3dq3zg",
        "outputId": "1fdf828c-56a5-4666-efce-79669e6dc2bf"
      },
      "source": [
        "# Define model\n",
        "model = nn.Linear(3, 2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.4375, -0.2529,  0.2407],\n",
            "        [-0.2481, -0.3997, -0.1724]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.5586,  0.0897], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlioavOjrtcR"
      },
      "source": [
        "PyTorch models also have a helpful `.parameters` method, which returns a list containing all the weights and bias matrices present in the model. In our model, we have one weight matrix and one bias matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-C0g7WIrpjN",
        "outputId": "fa171e17-11d5-473d-db52-ba461a5312b9"
      },
      "source": [
        "# Parameters\n",
        "list(model.parameters())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.4375, -0.2529,  0.2407],\n",
              "         [-0.2481, -0.3997, -0.1724]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.5586,  0.0897], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oib9VDLfr89t"
      },
      "source": [
        "We can use the model to generate predictions in the same way as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTLWjmc7r6I4",
        "outputId": "c5db0df3-92da-409b-a959-4df979a1a72d"
      },
      "source": [
        "# Generate predictions\n",
        "Y_ = model(X)\n",
        "print(Y_)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-39.0911, -52.2147],\n",
            "        [-47.2228, -68.6943],\n",
            "        [-58.5484, -85.0520],\n",
            "        [-47.1542, -48.7843],\n",
            "        [-38.1765, -67.4670],\n",
            "        [-39.2757, -52.0631],\n",
            "        [-46.7293, -68.4670],\n",
            "        [-58.7452, -85.4726],\n",
            "        [-46.9696, -48.9358],\n",
            "        [-37.4983, -67.3912],\n",
            "        [-38.5976, -51.9874],\n",
            "        [-47.4075, -68.5428],\n",
            "        [-59.0419, -85.2793],\n",
            "        [-47.8324, -48.8601],\n",
            "        [-37.9918, -67.6185]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHKLollYsHZT"
      },
      "source": [
        "### Loss Function\n",
        "Instead of defining a loss function manually, we can use the built-in loss function `mse_loss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGIQN-NVsFzc"
      },
      "source": [
        "# Import nn.functional\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfD0SJgtsUaY"
      },
      "source": [
        "The `nn.functional` package contains many useful loss functions and several other utilities. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t40rJpQZsSAK"
      },
      "source": [
        "# Define the Loss Function\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcRQguEhsdaJ"
      },
      "source": [
        "Compute the Loss for the current predictions (Y_) of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG6-yJ_Tscd4",
        "outputId": "f9479277-8b06-4593-91f0-9bb3f9007a9b"
      },
      "source": [
        "Loss = loss_fn(model(X), Y)\n",
        "print(Loss)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(21485.8887, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_DCIj1Msrhi"
      },
      "source": [
        "## Optimizer\n",
        "Instead of manually manipulating the model weights & biases using gradients as done before, we can use the optimizer `optim.SGD` - SGD stands for \"Stochastic Gradient Descent\". SGD selects samples in random batches, instead as a single group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTQe8eLXsY_K"
      },
      "source": [
        "# Define optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgHf0RWBtI9L"
      },
      "source": [
        "`model.parameters()` is passed as an argument to `optim.SGD` so that the optimizer knows which matrices should be modified during the update step. We can also specify a learning rate `lr` that controls the amount by which the parameters are modified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHqTGw5ytW9V"
      },
      "source": [
        "## Train the Model\n",
        "Training the model constitutes:\n",
        "* Generate predictions\n",
        "\n",
        "* Calculate the Loss\n",
        "\n",
        "* **Backpropogation**: Compute Gradients\n",
        "\n",
        "* **Update Step**: Update weights and biases by subtracting `gradient*lr`\n",
        "\n",
        "* Reset gradients to zero for the next iteration\n",
        "\n",
        "Here we work with batches of data instead of processing the entire training data in every iteration. \n",
        "\n",
        "Define a function `LinReg` that trains our Linear Regression model for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8zxtwyvtGCV"
      },
      "source": [
        "# Function to Train the model\n",
        "def LinReg(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    \n",
        "    # Repeat for all epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Train with batches of data\n",
        "        for xb,yb in train_dl:\n",
        "            \n",
        "            # Generate predictions\n",
        "            pred = model(xb)\n",
        "            \n",
        "            # Calculate the Loss\n",
        "            Loss = loss_fn(pred, yb)\n",
        "            \n",
        "            # Backprop\n",
        "            Loss.backward()\n",
        "            \n",
        "            # Update the parameters \n",
        "            opt.step()\n",
        "            \n",
        "            # Reset gradients to zero\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        # Print the Progress\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Loss: {Loss.item()}')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzrJHHiGvhzT"
      },
      "source": [
        "* Use `DataLoader` to get batches of data for every iteration.\n",
        "\n",
        "* We use `opt.step` to perform the update and `opt.zero_grad` to reset the gradients to zero.\n",
        "\n",
        "* Print the loss from the last batch of data for every 10th epoch to track training progress. `loss.item` returns the actual value stored in the loss tensor.\n",
        "\n",
        "Train the model for 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsIZkRX_ve1v",
        "outputId": "30781537-93b1-40c4-9d8d-153483c77892"
      },
      "source": [
        "LinReg(100, model, loss_fn, opt, train_dl)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10/100, Loss: 312.4222412109375\n",
            "Epoch: 20/100, Loss: 340.64935302734375\n",
            "Epoch: 30/100, Loss: 129.66961669921875\n",
            "Epoch: 40/100, Loss: 171.03321838378906\n",
            "Epoch: 50/100, Loss: 80.40342712402344\n",
            "Epoch: 60/100, Loss: 41.6878547668457\n",
            "Epoch: 70/100, Loss: 40.71399688720703\n",
            "Epoch: 80/100, Loss: 38.065940856933594\n",
            "Epoch: 90/100, Loss: 19.5218563079834\n",
            "Epoch: 100/100, Loss: 18.048315048217773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmdsdAsWwEY9"
      },
      "source": [
        "Print out the predictions and actual outputs and compare them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWxt16xbwABB",
        "outputId": "662aefdf-4a4b-4110-9db1-6b1b587cef01"
      },
      "source": [
        "print(f'Predictions: {model(X)}\\n')\n",
        "print(f'Actual Outputs: {Y}\\n')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions: tensor([[ 57.6125,  71.5877],\n",
            "        [ 82.5405,  98.3715],\n",
            "        [115.4930, 134.9106],\n",
            "        [ 25.5902,  45.0049],\n",
            "        [ 99.8847, 110.5835],\n",
            "        [ 56.5155,  70.6304],\n",
            "        [ 82.4459,  98.0328],\n",
            "        [115.8567, 135.3188],\n",
            "        [ 26.6872,  45.9623],\n",
            "        [100.8871, 111.2021],\n",
            "        [ 57.5178,  71.2490],\n",
            "        [ 81.4435,  97.4141],\n",
            "        [115.5876, 135.2493],\n",
            "        [ 24.5879,  44.3863],\n",
            "        [100.9817, 111.5408]], grad_fn=<AddmmBackward>)\n",
            "\n",
            "Actual Outputs: tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 57.,  69.],\n",
            "        [ 80., 102.],\n",
            "        [118., 132.],\n",
            "        [ 21.,  38.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [ 82., 100.],\n",
            "        [118., 134.],\n",
            "        [ 20.,  38.],\n",
            "        [102., 120.]])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPIVeuonweSi"
      },
      "source": [
        "For obtaining the prediction for a new input (Temperature, Rainfall and Humidity), we can pass a batch containing single row of input to our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-WWp3d_wZab",
        "outputId": "ffa47565-dedc-4535-e8c8-78177dc84d33"
      },
      "source": [
        "model(torch.tensor([[75, 63, 44.]]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[54.5462, 68.4821]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}